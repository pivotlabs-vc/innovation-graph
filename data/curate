#!/usr/bin/env python3

import os
import json
import csv
import sys

from rdflib import Graph, Literal, RDF, URIRef
from rdflib.namespace import XSD

LABEL=URIRef("http://www.w3.org/2000/01/rdf-schema#label")
DESCRIPTION=URIRef("http://pivotlabs.vc/challenges/p#description")
IS_A=URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type")
PROPERTY=URIRef("http://www.w3.org/2000/01/rdf-schema#Property")
CLASS=URIRef("http://www.w3.org/2000/01/rdf-schema#Class")

LABEL=URIRef("http://www.w3.org/2000/01/rdf-schema#label")

class MetadataError(Exception):
   def __init__(self, dir, msg):
      self.dir = dir
      super().__init__(msg)

class FileProcessingError(Exception):
   def __init__(self, file, msg):
      self.file = file
      super().__init__(msg)

class LineProcessingError(Exception):
   def __init__(self, file, line, msg):
      self.file = file
      self.line = line
      super().__init__(msg)

class PredicateNotKnown(Exception):
   def __init__(self, file, predicate, msg):
      self.file = file
      self.predicate = predicate
      super().__init__(msg)

namespaces = {
   "dc": "http://purl.org/dc/elements/1.1/",
   "property": "http://pivotlabs.vc/challenges/p#",
   "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
   "type": "http://pivotlabs.vc/challenges/",
   "source": "http://pivotlabs.vc/challenges/s/",
}

class Util:
   @staticmethod
   def map_ns(str):
      if str.startswith("http://"): return str
      if str.startswith("https://"): return str
      ix = str.find(":")
      if ix < 0: return str
      ns = str[0:ix]
      if ns not in namespaces: return str
      return namespaces[ns] + str[ix + 1:]
   @staticmethod
   def map(str):
      str = Util.map_ns(str)
      if str.startswith("http:"):
         return URIRef(str)
      if str.startswith("https:"):
         return URIRef(str)
      return Literal(str)

class Csv:

   @staticmethod
   def load(subdir, metadata, schema):

      g = Graph()

      if "input" not in metadata:
         raise MetadataError(subdir, "The 'input' field does not exist")

      if "fields" not in metadata:
         raise MetadataError(subdir, "The 'fields' field does not exist")

      if "id-prefix" not in metadata:
         raise MetadataError(subdir, "The 'id-prefix' field does not exist")

      path = subdir + "/" + metadata["input"]
      fields = metadata["fields"]
      prefix = metadata["id-prefix"]

      if len(fields) < 2:
         raise MetadataError(
            subdir, "Fields list must have at least 2 elements"
         )

      if fields[0] != "%%identity%%":
         raise MetadataError(
            subdir, "%%identity%% must be first element of fields list"
         )

      with open(path) as f:

         reader = csv.reader(f)
         line = 1

         for row in reader:

            if len(row) != len(fields):
               raise LineProcessingError(
                  path, line,
                  f"CSV row has {len(row)} cells, mismatches the field list"
               )

            triples = []
            for i in range(1, len(row)):
               s = Util.map(prefix + row[0])
               p = Util.map(fields[i])
               o = Util.map(row[i])

               if p not in schema.properties:
                  if  p not in schema.classes:
                     raise PredicateNotKnown(path, p, "Not known: " + str(p))

               g.add((s, p, o))

            line += 1

      c = Csv()
      c.graph = g
      return c

class Turtle:
   @staticmethod
   def load(subdir, metadata, schema):

      if "input" not in metadata:
         raise MetadataError(subdir, "The 'input' field does not exist")

      t = Turtle()

      g = Graph()

      path = subdir + "/" + metadata["input"]
      g.parse(source=open(path), format="turtle")

      for (s, p, o) in g:
         if p not in schema.properties:
            if p not in schema.classes:
               raise PredicateNotKnown(path, p, "Not known: " + str(p))

      t.graph = g

      return t

class Schema:

   def __init__(self):
      self.properties = {}
      self.classes = {}

   @staticmethod
   def load(path):

      s = Schema()

      g = Graph()
      g.parse(path, format="turtle")

      s.graph = g

      for tpl in g:
         if len(tpl) != 3:
            raise RuntimeError("Schema parsing unexpected triple failure")

         if tpl[1] == DESCRIPTION:
            pass
         if tpl[1] == LABEL:
            pass
         if tpl[1] == IS_A:
            if tpl[2] == PROPERTY:
               s.properties[tpl[0]] = True
            if tpl[2] == CLASS:
               s.classes[tpl[0]] = True

      s.properties[LABEL] = True
      s.properties[IS_A] = True

      return s

class Curator:
   
   processors = {
      "csv": Csv,
      "turtle": Turtle,
   }

   def __init__(self):

      self.schema = None

   def load_schema(self, path):

      sys.stderr.write("*** Loading schema\n")

      self.schema = Schema.load(path)

   def process(self, subdir):

      sys.stderr.write("*** Processing " + subdir + "...\n")
      metadata = json.load(open(subdir + "/metadata.json"))
      for field in [
            "id", "description", "contributors", "origin", "copyright",
            "processing"
      ]:
         if field not in metadata:
            raise MetadataError(subdir, f"The '{field}' field does not exist")

      if metadata["processing"] not in Curator.processors:
         msg = f"Processing type '{metadata['processing']}' is not understood."
         raise MetadataError(subdir, msg)
   
      cls = Curator.processors[metadata["processing"]]

      return cls.load(subdir, metadata, self.schema)
   
   def walk(self, dir):

      g = Graph()

      for subdir, dirs, files in os.walk(dir):
   
         ix_path = subdir + "/metadata.json"

         if not os.path.exists(ix_path):
            continue

         sg = self.process(subdir)

         for tpl in sg.graph:
            g.add(tpl)

      return g

if len(sys.argv) != 3:
   sys.stderr.write("Usage:\n")
   sys.stderr.write("    curate <data-dir> <schemafile>\n")
   sys.exit(1)

try:
   c = Curator()
   c.load_schema(sys.argv[2])
   g = c.walk(sys.argv[1])
except MetadataError as e:
   sys.stderr.write(f"Metadata error in {e.dir}: {e}\n")
except FileProcessingError as e:
   sys.stderr.write(f"Error in {e.file}: {e}\n")
except LineProcessingError as e:
   sys.stderr.write(f"Error in {e.file} line {e.line}: {e}\n")
except PredicateNotKnown as e:
   sys.stderr.write(f"Predicate {e.predicate} not known, parsing {e.file}\n")

print(g.serialize(format="turtle"))
